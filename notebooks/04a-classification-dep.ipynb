{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 31 2018 \n",
      "\n",
      "CPython 3.6.6\n",
      "IPython 6.5.0\n",
      "\n",
      "numpy 1.15.1\n",
      "scipy 1.1.0\n",
      "sklearn 0.19.1\n",
      "pandas 0.23.4\n",
      "\n",
      "compiler   : GCC 4.8.2 20140120 (Red Hat 4.8.2-15)\n",
      "system     : Linux\n",
      "release    : 4.9.0-7-amd64\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 12\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext watermark\n",
    "%watermark -v -n -m -p numpy,scipy,sklearn,pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/kovar/thesis_project/data/processed/1a.fif...\n",
      "This filename (/home/kovar/thesis_project/data/processed/1a.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz or raw_tsss.fif.gz\n",
      "Isotrak not found\n",
      "    Range : 0 ... 19104 =      0.000 ...    76.416 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-2bb109ef8967>:25: RuntimeWarning: This filename (/home/kovar/thesis_project/data/processed/1a.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz or raw_tsss.fif.gz\n",
      "  raw_fif = mne.io.read_raw_fif(os.path.join(PROCESSED_ROOT, '1a.fif'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>resp</th>\n",
       "      <th>b/a</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sfreq</th>\n",
       "      <th>sc</th>\n",
       "      <th>sc_bef</th>\n",
       "      <th>sc_aft</th>\n",
       "      <th>dep</th>\n",
       "      <th>dep_bef</th>\n",
       "      <th>dep_aft</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>250</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>250</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>250</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>250</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>250</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>250</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>250</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>250</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>250</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>250</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>250</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>250</td>\n",
       "      <td>27.0</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>250</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>250</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">15</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">119</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>250</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>250</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">120</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">121</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>250</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">122</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>250</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>250</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">123</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>250</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>250</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">124</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>250</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>250</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">125</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>250</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">126</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>250</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>250</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">127</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>250</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>250</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">128</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>250</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>250</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">129</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>250</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>250</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">130</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">131</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>250</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>250</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">132</th>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>250</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>250</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">133</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>250</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              resp b/a sex  age  sfreq    sc  sc_bef  sc_aft  dep  dep_bef  \\\n",
       "patient trial                                                                \n",
       "1       a        1   0   0   49    250  26.0      26      13    0        0   \n",
       "        b        1   1   0   49    250  13.0      26      13   -1        0   \n",
       "2       a        0   0   0   36    250  31.0      31      30    1        1   \n",
       "        b        0   1   0   36    250  30.0      31      30    1        1   \n",
       "3       a        1   0   0   48    250  25.0      25       7    0       -1   \n",
       "        b        1   1   0   48    250   7.0      25       7   -1       -1   \n",
       "4       a        0   0   0   55    250  26.0      26      25    0        0   \n",
       "        b        0   1   0   55    250  25.0      26      25    0        0   \n",
       "5       a        0   0   0   35    250  26.0      26      37    0        0   \n",
       "        b        0   1   0   35    250  37.0      26      37    1        0   \n",
       "6       a        0   0   0   37    250  31.0      31      17    1        1   \n",
       "        b        0   1   0   37    250  17.0      31      17   -1        1   \n",
       "7       a        0   0   0   63    250  30.0      30      25    1        1   \n",
       "        b        0   1   0   63    250  25.0      30      25    0        1   \n",
       "8       a        1   0   1   50    250  24.0      24      11    0       -1   \n",
       "        b        1   1   1   50    250  11.0      24      11   -1       -1   \n",
       "9       a        0   0   1   59    250  34.0      34      27    1        1   \n",
       "        b        0   1   1   59    250  27.0      34      27    1        1   \n",
       "10      a        1   0   0   49    250  36.0      36      17    1        1   \n",
       "        b        1   1   0   49    250  17.0      36      17   -1        1   \n",
       "11      a        0   0   1   53   1000  27.0      27      26    1        0   \n",
       "        b        0   1   1   53   1000  26.0      27      26    0        0   \n",
       "12      a        1   0   1   59   1000  30.0      30      12    1        1   \n",
       "        b        1   1   1   59   1000  12.0      30      12   -1        1   \n",
       "13      a        1   0   0   57    250  26.0      26       7    0        0   \n",
       "        b        1   1   0   57    250   7.0      26       7   -1        0   \n",
       "14      a        0   0   0   30    250  28.0      28      17    1        0   \n",
       "        b        0   1   0   30    250  17.0      28      17   -1        0   \n",
       "15      a        1   0   0   35   1000  25.0      25       3    0       -1   \n",
       "        b        1   1   0   35   1000   3.0      25       3   -1       -1   \n",
       "...            ...  ..  ..  ...    ...   ...     ...     ...  ...      ...   \n",
       "119     a        1   0   1   61    250  23.0      23       4    0       -1   \n",
       "        b        1   1   1   61    250   4.0      23       4   -1       -1   \n",
       "120     a        0   0   0   41   1000  28.0      28      19    1        0   \n",
       "        b        0   1   0   41   1000  19.0      28      19   -1        0   \n",
       "121     a        0   0   0   34    250  24.0      24      26    0       -1   \n",
       "        b        0   1   0   34    250  26.0      24      26    0       -1   \n",
       "122     a        0   0   1   55    250  35.0      35      19    1        1   \n",
       "        b        0   1   1   55    250  19.0      35      19   -1        1   \n",
       "123     a        0   0   1   54    250  24.0      24      25    0       -1   \n",
       "        b        0   1   1   54    250  25.0      24      25    0       -1   \n",
       "124     a        0   0   0   52    250  30.0      30      23    1        1   \n",
       "        b        0   1   0   52    250  23.0      30      23    0        1   \n",
       "125     a        1   0   0   56    250  26.0      26      11    0        0   \n",
       "        b        1   1   0   56    250  11.0      26      11   -1        0   \n",
       "126     a        0   0   0   40    250  25.0      25      17    0       -1   \n",
       "        b        0   1   0   40    250  17.0      25      17   -1       -1   \n",
       "127     a        0   0   0   35    250  25.0      25      21    0       -1   \n",
       "        b        0   1   0   35    250  21.0      25      21    0       -1   \n",
       "128     a        1   0   0   51    250  21.0      21       9    0       -1   \n",
       "        b        1   1   0   51    250   9.0      21       9   -1       -1   \n",
       "129     a        1   0   0   38    250  27.0      27       6    1        0   \n",
       "        b        1   1   0   38    250   6.0      27       6   -1        0   \n",
       "130     a        0   0   0   38   1000  31.0      31      18    1        1   \n",
       "        b        0   1   0   38   1000  18.0      31      18   -1        1   \n",
       "131     a        0   0   0   35    250  25.0      25      17    0       -1   \n",
       "        b        0   1   0   35    250  17.0      25      17   -1       -1   \n",
       "132     a        1   0   0   55    250  27.0      27      10    1        0   \n",
       "        b        1   1   0   55    250  10.0      27      10   -1        0   \n",
       "133     a        0   0   0   64    250  33.0      33      27    1        1   \n",
       "        b        0   1   0   64    250  27.0      33      27    1        1   \n",
       "\n",
       "               dep_aft    change  \n",
       "patient trial                     \n",
       "1       a            0  2.000000  \n",
       "        b            0  2.000000  \n",
       "2       a            1  1.033333  \n",
       "        b            1  1.033333  \n",
       "3       a           -1  3.571429  \n",
       "        b           -1  3.571429  \n",
       "4       a            1  1.040000  \n",
       "        b            1  1.040000  \n",
       "5       a            1  0.702703  \n",
       "        b            1  0.702703  \n",
       "6       a            0  1.823529  \n",
       "        b            0  1.823529  \n",
       "7       a            1  1.200000  \n",
       "        b            1  1.200000  \n",
       "8       a           -1  2.181818  \n",
       "        b           -1  2.181818  \n",
       "9       a            1  1.259259  \n",
       "        b            1  1.259259  \n",
       "10      a            0  2.117647  \n",
       "        b            0  2.117647  \n",
       "11      a            1  1.038462  \n",
       "        b            1  1.038462  \n",
       "12      a           -1  2.500000  \n",
       "        b           -1  2.500000  \n",
       "13      a           -1  3.714286  \n",
       "        b           -1  3.714286  \n",
       "14      a            0  1.647059  \n",
       "        b            0  1.647059  \n",
       "15      a           -1  8.333333  \n",
       "        b           -1  8.333333  \n",
       "...                ...       ...  \n",
       "119     a           -1  5.750000  \n",
       "        b           -1  5.750000  \n",
       "120     a            0  1.473684  \n",
       "        b            0  1.473684  \n",
       "121     a            1  0.923077  \n",
       "        b            1  0.923077  \n",
       "122     a            0  1.842105  \n",
       "        b            0  1.842105  \n",
       "123     a            1  0.960000  \n",
       "        b            1  0.960000  \n",
       "124     a            1  1.304348  \n",
       "        b            1  1.304348  \n",
       "125     a           -1  2.363636  \n",
       "        b           -1  2.363636  \n",
       "126     a            0  1.470588  \n",
       "        b            0  1.470588  \n",
       "127     a            1  1.190476  \n",
       "        b            1  1.190476  \n",
       "128     a           -1  2.333333  \n",
       "        b           -1  2.333333  \n",
       "129     a           -1  4.500000  \n",
       "        b           -1  4.500000  \n",
       "130     a            0  1.722222  \n",
       "        b            0  1.722222  \n",
       "131     a            0  1.470588  \n",
       "        b            0  1.470588  \n",
       "132     a           -1  2.700000  \n",
       "        b           -1  2.700000  \n",
       "133     a            1  1.222222  \n",
       "        b            1  1.222222  \n",
       "\n",
       "[266 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import nolds\n",
    "import data\n",
    "import mne\n",
    "\n",
    "PROJ_ROOT = os.path.abspath(os.path.join(os.pardir))\n",
    "DATA_ROOT = os.path.abspath(os.path.join(PROJ_ROOT, 'data'))\n",
    "PROCESSED_ROOT = os.path.abspath(os.path.join(DATA_ROOT, 'processed'))\n",
    "RAW_ROOT = os.path.abspath(os.path.join(DATA_ROOT, 'raw'))\n",
    "LABELED_ROOT = os.path.abspath(os.path.join(DATA_ROOT, 'labeled'))\n",
    "DURATIONS_ROOT = os.path.abspath(os.path.join(DATA_ROOT, 'durations'))\n",
    "sys.path.append(os.path.join(PROJ_ROOT, 'src'))\n",
    "CHANNEL_NAMES = ['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "                 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']\n",
    "META_COLUMN_NAMES = ['freq', 'RESP_4W', 'RESP_FIN', 'REMISE_FIN', 'AGE', 'SEX', 'M_1',\n",
    "       'M_4', 'M_F', 'délka léčby', 'lék 1', 'lék 2', 'lék 3', 'lék 4']\n",
    "META_FILE_NAME = 'DEP-POOL_Final_144.xlsx'\n",
    "meta_df = pd.read_excel(os.path.join(RAW_ROOT, META_FILE_NAME), index_col='ID', names=META_COLUMN_NAMES)\n",
    "\n",
    "raw_fif = mne.io.read_raw_fif(os.path.join(PROCESSED_ROOT, '1a.fif'))\n",
    "t = pd.DataFrame(raw_fif.get_data())\n",
    "data = pd.DataFrame(np.transpose(t.values), columns=CHANNEL_NAMES)\n",
    "data = np.transpose(data.values)\n",
    "metapkl = pd.read_pickle(os.path.join(LABELED_ROOT, 'processed', 'meta', 'meta.pkl'))\n",
    "metapkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    198\n",
      " 1     34\n",
      "-1     34\n",
      "Name: dep, dtype: int64\n",
      "0    208\n",
      "1     58\n",
      "Name: dep_bef, dtype: int64\n",
      " 0    188\n",
      "-1     68\n",
      " 1     10\n",
      "Name: dep_aft, dtype: int64\n",
      " 1    90\n",
      " 0    88\n",
      "-1    88\n",
      "Name: resp, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def f(row, col):\n",
    "    if row[col] <= 10:\n",
    "        return -1\n",
    "    if row[col] <= 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def ff(row, col, n=5):\n",
    "    for i in range(n):\n",
    "        if row[col] <= metapkl.quantile((i+1)/n)[col]:\n",
    "            return i\n",
    "    \n",
    "metapkl['dep'] = metapkl.apply(lambda row: f(row, 'sc'), axis=1)\n",
    "metapkl['dep_bef'] = metapkl.apply(lambda row: f(row, 'sc_bef'), axis=1)\n",
    "metapkl['dep_aft'] = metapkl.apply(lambda row: f(row, 'sc_aft'), axis=1)\n",
    "metapkl = metapkl.astype({'dep': 'category', 'dep_bef': 'category', 'dep_aft': 'category'})                                           \n",
    "print(metapkl['dep'].value_counts())\n",
    "print(metapkl['dep_bef'].value_counts())\n",
    "print(metapkl['dep_aft'].value_counts())\n",
    "def f(row, col):\n",
    "    if row[col] <= metapkl.quantile(0.33)['change']:\n",
    "        return -1\n",
    "    if row[col] <= metapkl.quantile(0.66)['change']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "metapkl['resp'] = metapkl.apply(lambda row: f(row, 'change'), axis=1)\n",
    "metapkl = metapkl.astype({'resp': 'category'})                                           \n",
    "print(metapkl['resp'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (2 levels on the left, 1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>channel</th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "      <th>Pz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "      <th>hurst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753999</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.664204</td>\n",
       "      <td>0.797222</td>\n",
       "      <td>0.717136</td>\n",
       "      <td>0.670598</td>\n",
       "      <td>0.717158</td>\n",
       "      <td>0.729203</td>\n",
       "      <td>0.719521</td>\n",
       "      <td>0.714822</td>\n",
       "      <td>0.827080</td>\n",
       "      <td>0.739173</td>\n",
       "      <td>0.741375</td>\n",
       "      <td>0.683406</td>\n",
       "      <td>0.732182</td>\n",
       "      <td>0.685296</td>\n",
       "      <td>0.741297</td>\n",
       "      <td>0.696825</td>\n",
       "      <td>0.734869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.483106</td>\n",
       "      <td>0.553749</td>\n",
       "      <td>0.325695</td>\n",
       "      <td>0.478609</td>\n",
       "      <td>0.357043</td>\n",
       "      <td>0.346590</td>\n",
       "      <td>0.331214</td>\n",
       "      <td>0.361492</td>\n",
       "      <td>0.311310</td>\n",
       "      <td>0.345450</td>\n",
       "      <td>0.488038</td>\n",
       "      <td>0.517441</td>\n",
       "      <td>0.370669</td>\n",
       "      <td>0.414256</td>\n",
       "      <td>0.310522</td>\n",
       "      <td>0.359430</td>\n",
       "      <td>0.366019</td>\n",
       "      <td>0.382168</td>\n",
       "      <td>0.321377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.590308</td>\n",
       "      <td>0.541832</td>\n",
       "      <td>0.408367</td>\n",
       "      <td>0.522805</td>\n",
       "      <td>0.420881</td>\n",
       "      <td>0.421173</td>\n",
       "      <td>0.317976</td>\n",
       "      <td>0.387284</td>\n",
       "      <td>0.342726</td>\n",
       "      <td>0.433125</td>\n",
       "      <td>0.618258</td>\n",
       "      <td>0.565268</td>\n",
       "      <td>0.548987</td>\n",
       "      <td>0.660894</td>\n",
       "      <td>0.355150</td>\n",
       "      <td>0.372977</td>\n",
       "      <td>0.392740</td>\n",
       "      <td>0.306597</td>\n",
       "      <td>0.343313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.660602</td>\n",
       "      <td>0.671559</td>\n",
       "      <td>0.486952</td>\n",
       "      <td>0.552988</td>\n",
       "      <td>0.475865</td>\n",
       "      <td>0.490763</td>\n",
       "      <td>0.469610</td>\n",
       "      <td>0.396751</td>\n",
       "      <td>0.421887</td>\n",
       "      <td>0.443163</td>\n",
       "      <td>0.586962</td>\n",
       "      <td>0.650928</td>\n",
       "      <td>0.528124</td>\n",
       "      <td>0.576462</td>\n",
       "      <td>0.448159</td>\n",
       "      <td>0.357141</td>\n",
       "      <td>0.532884</td>\n",
       "      <td>0.582378</td>\n",
       "      <td>0.510804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.639096</td>\n",
       "      <td>0.639857</td>\n",
       "      <td>0.553844</td>\n",
       "      <td>0.554577</td>\n",
       "      <td>0.461236</td>\n",
       "      <td>0.365423</td>\n",
       "      <td>0.436752</td>\n",
       "      <td>0.470169</td>\n",
       "      <td>0.433260</td>\n",
       "      <td>0.455148</td>\n",
       "      <td>0.674387</td>\n",
       "      <td>0.679535</td>\n",
       "      <td>0.552409</td>\n",
       "      <td>0.571673</td>\n",
       "      <td>0.334882</td>\n",
       "      <td>0.379694</td>\n",
       "      <td>0.507433</td>\n",
       "      <td>0.533982</td>\n",
       "      <td>0.557498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.614442</td>\n",
       "      <td>0.635342</td>\n",
       "      <td>0.638403</td>\n",
       "      <td>0.622358</td>\n",
       "      <td>0.616017</td>\n",
       "      <td>0.606111</td>\n",
       "      <td>0.673701</td>\n",
       "      <td>0.580958</td>\n",
       "      <td>0.553440</td>\n",
       "      <td>0.654507</td>\n",
       "      <td>0.693509</td>\n",
       "      <td>0.692508</td>\n",
       "      <td>0.589098</td>\n",
       "      <td>0.639489</td>\n",
       "      <td>0.526527</td>\n",
       "      <td>0.632429</td>\n",
       "      <td>0.591804</td>\n",
       "      <td>0.619130</td>\n",
       "      <td>0.577964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.724055</td>\n",
       "      <td>0.739994</td>\n",
       "      <td>0.641489</td>\n",
       "      <td>0.592656</td>\n",
       "      <td>0.590430</td>\n",
       "      <td>0.590867</td>\n",
       "      <td>0.594284</td>\n",
       "      <td>0.610117</td>\n",
       "      <td>0.523190</td>\n",
       "      <td>0.615968</td>\n",
       "      <td>0.657750</td>\n",
       "      <td>0.670664</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>0.600417</td>\n",
       "      <td>0.546664</td>\n",
       "      <td>0.595402</td>\n",
       "      <td>0.619127</td>\n",
       "      <td>0.621813</td>\n",
       "      <td>0.633788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.597459</td>\n",
       "      <td>0.661764</td>\n",
       "      <td>0.642293</td>\n",
       "      <td>0.652749</td>\n",
       "      <td>0.624995</td>\n",
       "      <td>0.705735</td>\n",
       "      <td>0.432528</td>\n",
       "      <td>0.449657</td>\n",
       "      <td>0.538968</td>\n",
       "      <td>0.493138</td>\n",
       "      <td>0.683530</td>\n",
       "      <td>0.767805</td>\n",
       "      <td>0.592404</td>\n",
       "      <td>0.754489</td>\n",
       "      <td>0.449896</td>\n",
       "      <td>0.616261</td>\n",
       "      <td>0.604243</td>\n",
       "      <td>0.631332</td>\n",
       "      <td>0.613122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.832184</td>\n",
       "      <td>0.744612</td>\n",
       "      <td>0.707344</td>\n",
       "      <td>0.625504</td>\n",
       "      <td>0.652221</td>\n",
       "      <td>0.723436</td>\n",
       "      <td>0.739239</td>\n",
       "      <td>0.601584</td>\n",
       "      <td>0.597490</td>\n",
       "      <td>0.567407</td>\n",
       "      <td>0.776553</td>\n",
       "      <td>0.806508</td>\n",
       "      <td>0.713681</td>\n",
       "      <td>0.763915</td>\n",
       "      <td>0.576701</td>\n",
       "      <td>0.574221</td>\n",
       "      <td>0.576993</td>\n",
       "      <td>0.615871</td>\n",
       "      <td>0.747924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.820025</td>\n",
       "      <td>0.836417</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>0.695366</td>\n",
       "      <td>0.718106</td>\n",
       "      <td>0.751496</td>\n",
       "      <td>0.701602</td>\n",
       "      <td>0.651476</td>\n",
       "      <td>0.646323</td>\n",
       "      <td>0.606984</td>\n",
       "      <td>0.779284</td>\n",
       "      <td>0.772223</td>\n",
       "      <td>0.767590</td>\n",
       "      <td>0.695606</td>\n",
       "      <td>0.745911</td>\n",
       "      <td>0.594952</td>\n",
       "      <td>0.766869</td>\n",
       "      <td>0.704392</td>\n",
       "      <td>0.708301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.789668</td>\n",
       "      <td>0.768005</td>\n",
       "      <td>0.669128</td>\n",
       "      <td>0.662312</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.673983</td>\n",
       "      <td>0.671491</td>\n",
       "      <td>0.732512</td>\n",
       "      <td>0.672579</td>\n",
       "      <td>0.684480</td>\n",
       "      <td>0.751451</td>\n",
       "      <td>0.744030</td>\n",
       "      <td>0.784964</td>\n",
       "      <td>0.567166</td>\n",
       "      <td>0.768244</td>\n",
       "      <td>0.700240</td>\n",
       "      <td>0.616308</td>\n",
       "      <td>0.632860</td>\n",
       "      <td>0.685826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.597817</td>\n",
       "      <td>0.607292</td>\n",
       "      <td>0.527661</td>\n",
       "      <td>0.557764</td>\n",
       "      <td>0.561065</td>\n",
       "      <td>0.602014</td>\n",
       "      <td>0.551127</td>\n",
       "      <td>0.551095</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.492067</td>\n",
       "      <td>0.665394</td>\n",
       "      <td>0.690520</td>\n",
       "      <td>0.622802</td>\n",
       "      <td>0.612296</td>\n",
       "      <td>0.529462</td>\n",
       "      <td>0.533588</td>\n",
       "      <td>0.534114</td>\n",
       "      <td>0.616742</td>\n",
       "      <td>0.571664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.554936</td>\n",
       "      <td>0.557657</td>\n",
       "      <td>0.515685</td>\n",
       "      <td>0.485301</td>\n",
       "      <td>0.424117</td>\n",
       "      <td>0.467076</td>\n",
       "      <td>0.436336</td>\n",
       "      <td>0.442464</td>\n",
       "      <td>0.531152</td>\n",
       "      <td>0.462059</td>\n",
       "      <td>0.604143</td>\n",
       "      <td>0.671797</td>\n",
       "      <td>0.489966</td>\n",
       "      <td>0.485221</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.395726</td>\n",
       "      <td>0.447290</td>\n",
       "      <td>0.492999</td>\n",
       "      <td>0.502222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.688870</td>\n",
       "      <td>0.655660</td>\n",
       "      <td>0.598123</td>\n",
       "      <td>0.583084</td>\n",
       "      <td>0.577431</td>\n",
       "      <td>0.542526</td>\n",
       "      <td>0.592951</td>\n",
       "      <td>0.529432</td>\n",
       "      <td>0.627100</td>\n",
       "      <td>0.581733</td>\n",
       "      <td>0.665180</td>\n",
       "      <td>0.734811</td>\n",
       "      <td>0.530739</td>\n",
       "      <td>0.525505</td>\n",
       "      <td>0.486485</td>\n",
       "      <td>0.508242</td>\n",
       "      <td>0.616264</td>\n",
       "      <td>0.614816</td>\n",
       "      <td>0.599599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.616511</td>\n",
       "      <td>0.631594</td>\n",
       "      <td>0.553669</td>\n",
       "      <td>0.593662</td>\n",
       "      <td>0.467794</td>\n",
       "      <td>0.432599</td>\n",
       "      <td>0.494526</td>\n",
       "      <td>0.389230</td>\n",
       "      <td>0.542843</td>\n",
       "      <td>0.545380</td>\n",
       "      <td>0.573196</td>\n",
       "      <td>0.638432</td>\n",
       "      <td>0.528256</td>\n",
       "      <td>0.588995</td>\n",
       "      <td>0.463325</td>\n",
       "      <td>0.458552</td>\n",
       "      <td>0.350943</td>\n",
       "      <td>0.539782</td>\n",
       "      <td>0.512350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.636589</td>\n",
       "      <td>0.675734</td>\n",
       "      <td>0.564011</td>\n",
       "      <td>0.459885</td>\n",
       "      <td>0.496038</td>\n",
       "      <td>0.471468</td>\n",
       "      <td>0.431317</td>\n",
       "      <td>0.444567</td>\n",
       "      <td>0.498204</td>\n",
       "      <td>0.441731</td>\n",
       "      <td>0.621997</td>\n",
       "      <td>0.612477</td>\n",
       "      <td>0.503876</td>\n",
       "      <td>0.536234</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>0.412310</td>\n",
       "      <td>0.532143</td>\n",
       "      <td>0.543729</td>\n",
       "      <td>0.552986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.613727</td>\n",
       "      <td>0.660269</td>\n",
       "      <td>0.642280</td>\n",
       "      <td>0.636919</td>\n",
       "      <td>0.663253</td>\n",
       "      <td>0.578787</td>\n",
       "      <td>0.591345</td>\n",
       "      <td>0.568625</td>\n",
       "      <td>0.480604</td>\n",
       "      <td>0.513130</td>\n",
       "      <td>0.672477</td>\n",
       "      <td>0.715719</td>\n",
       "      <td>0.584699</td>\n",
       "      <td>0.567199</td>\n",
       "      <td>0.484293</td>\n",
       "      <td>0.420215</td>\n",
       "      <td>0.539484</td>\n",
       "      <td>0.566527</td>\n",
       "      <td>0.561603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.615167</td>\n",
       "      <td>0.661889</td>\n",
       "      <td>0.617417</td>\n",
       "      <td>0.590063</td>\n",
       "      <td>0.555753</td>\n",
       "      <td>0.569368</td>\n",
       "      <td>0.542934</td>\n",
       "      <td>0.567487</td>\n",
       "      <td>0.537803</td>\n",
       "      <td>0.538646</td>\n",
       "      <td>0.619918</td>\n",
       "      <td>0.691923</td>\n",
       "      <td>0.581501</td>\n",
       "      <td>0.731185</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>0.580824</td>\n",
       "      <td>0.566481</td>\n",
       "      <td>0.619558</td>\n",
       "      <td>0.492312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.690701</td>\n",
       "      <td>0.670268</td>\n",
       "      <td>0.524618</td>\n",
       "      <td>0.589364</td>\n",
       "      <td>0.597560</td>\n",
       "      <td>0.539645</td>\n",
       "      <td>0.505840</td>\n",
       "      <td>0.567339</td>\n",
       "      <td>0.532469</td>\n",
       "      <td>0.574016</td>\n",
       "      <td>0.686415</td>\n",
       "      <td>0.655458</td>\n",
       "      <td>0.606180</td>\n",
       "      <td>0.535414</td>\n",
       "      <td>0.449336</td>\n",
       "      <td>0.444196</td>\n",
       "      <td>0.523479</td>\n",
       "      <td>0.541581</td>\n",
       "      <td>0.576123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.603308</td>\n",
       "      <td>0.591698</td>\n",
       "      <td>0.569239</td>\n",
       "      <td>0.552218</td>\n",
       "      <td>0.555800</td>\n",
       "      <td>0.563258</td>\n",
       "      <td>0.539206</td>\n",
       "      <td>0.552314</td>\n",
       "      <td>0.366545</td>\n",
       "      <td>0.370824</td>\n",
       "      <td>0.628278</td>\n",
       "      <td>0.659876</td>\n",
       "      <td>0.589466</td>\n",
       "      <td>0.610678</td>\n",
       "      <td>0.516875</td>\n",
       "      <td>0.463122</td>\n",
       "      <td>0.574401</td>\n",
       "      <td>0.607276</td>\n",
       "      <td>0.542476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.623602</td>\n",
       "      <td>0.662135</td>\n",
       "      <td>0.502522</td>\n",
       "      <td>0.550089</td>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.496693</td>\n",
       "      <td>0.317475</td>\n",
       "      <td>0.394382</td>\n",
       "      <td>0.331280</td>\n",
       "      <td>0.349934</td>\n",
       "      <td>0.513452</td>\n",
       "      <td>0.650354</td>\n",
       "      <td>0.471623</td>\n",
       "      <td>0.603120</td>\n",
       "      <td>0.381586</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.527748</td>\n",
       "      <td>0.480016</td>\n",
       "      <td>0.357814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.560730</td>\n",
       "      <td>0.592633</td>\n",
       "      <td>0.552116</td>\n",
       "      <td>0.527454</td>\n",
       "      <td>0.558303</td>\n",
       "      <td>0.506181</td>\n",
       "      <td>0.516698</td>\n",
       "      <td>0.384636</td>\n",
       "      <td>0.475224</td>\n",
       "      <td>0.478286</td>\n",
       "      <td>0.627682</td>\n",
       "      <td>0.599159</td>\n",
       "      <td>0.521553</td>\n",
       "      <td>0.583006</td>\n",
       "      <td>0.476249</td>\n",
       "      <td>0.424452</td>\n",
       "      <td>0.591344</td>\n",
       "      <td>0.584282</td>\n",
       "      <td>0.635061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.542512</td>\n",
       "      <td>0.490586</td>\n",
       "      <td>0.481522</td>\n",
       "      <td>0.413476</td>\n",
       "      <td>0.534348</td>\n",
       "      <td>0.468061</td>\n",
       "      <td>0.323943</td>\n",
       "      <td>0.397307</td>\n",
       "      <td>0.353085</td>\n",
       "      <td>0.336942</td>\n",
       "      <td>0.610790</td>\n",
       "      <td>0.572107</td>\n",
       "      <td>0.495354</td>\n",
       "      <td>0.542791</td>\n",
       "      <td>0.329097</td>\n",
       "      <td>0.526325</td>\n",
       "      <td>0.376672</td>\n",
       "      <td>0.368591</td>\n",
       "      <td>0.409087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.691098</td>\n",
       "      <td>0.700826</td>\n",
       "      <td>0.692508</td>\n",
       "      <td>0.626029</td>\n",
       "      <td>0.621230</td>\n",
       "      <td>0.579140</td>\n",
       "      <td>0.565149</td>\n",
       "      <td>0.543224</td>\n",
       "      <td>0.606029</td>\n",
       "      <td>0.655466</td>\n",
       "      <td>0.705276</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>0.723215</td>\n",
       "      <td>0.671282</td>\n",
       "      <td>0.568964</td>\n",
       "      <td>0.795011</td>\n",
       "      <td>0.629653</td>\n",
       "      <td>0.611330</td>\n",
       "      <td>0.576465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.772660</td>\n",
       "      <td>0.791092</td>\n",
       "      <td>0.706712</td>\n",
       "      <td>0.759470</td>\n",
       "      <td>0.672674</td>\n",
       "      <td>0.649862</td>\n",
       "      <td>0.682524</td>\n",
       "      <td>0.636064</td>\n",
       "      <td>0.563478</td>\n",
       "      <td>0.745035</td>\n",
       "      <td>0.751163</td>\n",
       "      <td>0.747550</td>\n",
       "      <td>0.784203</td>\n",
       "      <td>0.724447</td>\n",
       "      <td>0.683318</td>\n",
       "      <td>0.737370</td>\n",
       "      <td>0.579085</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.616067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.702028</td>\n",
       "      <td>0.687744</td>\n",
       "      <td>0.541059</td>\n",
       "      <td>0.553816</td>\n",
       "      <td>0.578532</td>\n",
       "      <td>0.489232</td>\n",
       "      <td>0.616714</td>\n",
       "      <td>0.584733</td>\n",
       "      <td>0.502965</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.646079</td>\n",
       "      <td>0.634877</td>\n",
       "      <td>0.543536</td>\n",
       "      <td>0.529998</td>\n",
       "      <td>0.512648</td>\n",
       "      <td>0.529143</td>\n",
       "      <td>0.572759</td>\n",
       "      <td>0.523568</td>\n",
       "      <td>0.601014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.607256</td>\n",
       "      <td>0.563812</td>\n",
       "      <td>0.416201</td>\n",
       "      <td>0.500108</td>\n",
       "      <td>0.430466</td>\n",
       "      <td>0.387784</td>\n",
       "      <td>0.386542</td>\n",
       "      <td>0.375168</td>\n",
       "      <td>0.449297</td>\n",
       "      <td>0.478660</td>\n",
       "      <td>0.486930</td>\n",
       "      <td>0.551394</td>\n",
       "      <td>0.380094</td>\n",
       "      <td>0.422741</td>\n",
       "      <td>0.363737</td>\n",
       "      <td>0.410484</td>\n",
       "      <td>0.530046</td>\n",
       "      <td>0.431840</td>\n",
       "      <td>0.485700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.458505</td>\n",
       "      <td>0.453774</td>\n",
       "      <td>0.396653</td>\n",
       "      <td>0.367255</td>\n",
       "      <td>0.372247</td>\n",
       "      <td>0.408980</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.344535</td>\n",
       "      <td>0.362897</td>\n",
       "      <td>0.392919</td>\n",
       "      <td>0.624242</td>\n",
       "      <td>0.603409</td>\n",
       "      <td>0.450363</td>\n",
       "      <td>0.547260</td>\n",
       "      <td>0.330751</td>\n",
       "      <td>0.320241</td>\n",
       "      <td>0.357159</td>\n",
       "      <td>0.409132</td>\n",
       "      <td>0.367891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.776192</td>\n",
       "      <td>0.846239</td>\n",
       "      <td>0.700580</td>\n",
       "      <td>0.659454</td>\n",
       "      <td>0.700208</td>\n",
       "      <td>0.697899</td>\n",
       "      <td>0.656419</td>\n",
       "      <td>0.625929</td>\n",
       "      <td>0.758093</td>\n",
       "      <td>0.683897</td>\n",
       "      <td>0.796750</td>\n",
       "      <td>0.820124</td>\n",
       "      <td>0.667095</td>\n",
       "      <td>0.846803</td>\n",
       "      <td>0.623428</td>\n",
       "      <td>0.726842</td>\n",
       "      <td>0.705323</td>\n",
       "      <td>0.714835</td>\n",
       "      <td>0.671352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.805447</td>\n",
       "      <td>0.799487</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>0.814419</td>\n",
       "      <td>0.689170</td>\n",
       "      <td>0.671269</td>\n",
       "      <td>0.681100</td>\n",
       "      <td>0.700588</td>\n",
       "      <td>0.702219</td>\n",
       "      <td>0.696712</td>\n",
       "      <td>0.753699</td>\n",
       "      <td>0.805501</td>\n",
       "      <td>0.730594</td>\n",
       "      <td>0.751616</td>\n",
       "      <td>0.765304</td>\n",
       "      <td>0.715046</td>\n",
       "      <td>0.744174</td>\n",
       "      <td>0.661660</td>\n",
       "      <td>0.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.536939</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.344031</td>\n",
       "      <td>0.359802</td>\n",
       "      <td>0.428282</td>\n",
       "      <td>0.316459</td>\n",
       "      <td>0.418508</td>\n",
       "      <td>0.352303</td>\n",
       "      <td>0.301375</td>\n",
       "      <td>0.251577</td>\n",
       "      <td>0.557938</td>\n",
       "      <td>0.577904</td>\n",
       "      <td>0.456063</td>\n",
       "      <td>0.439480</td>\n",
       "      <td>0.306535</td>\n",
       "      <td>0.307516</td>\n",
       "      <td>0.331909</td>\n",
       "      <td>0.351794</td>\n",
       "      <td>0.467706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.742351</td>\n",
       "      <td>0.725569</td>\n",
       "      <td>0.591421</td>\n",
       "      <td>0.568121</td>\n",
       "      <td>0.527010</td>\n",
       "      <td>0.525995</td>\n",
       "      <td>0.543318</td>\n",
       "      <td>0.559898</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.548919</td>\n",
       "      <td>0.735847</td>\n",
       "      <td>0.677587</td>\n",
       "      <td>0.641948</td>\n",
       "      <td>0.645336</td>\n",
       "      <td>0.563834</td>\n",
       "      <td>0.430974</td>\n",
       "      <td>0.576052</td>\n",
       "      <td>0.611643</td>\n",
       "      <td>0.609181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.659493</td>\n",
       "      <td>0.658699</td>\n",
       "      <td>0.553942</td>\n",
       "      <td>0.572075</td>\n",
       "      <td>0.581594</td>\n",
       "      <td>0.585257</td>\n",
       "      <td>0.541289</td>\n",
       "      <td>0.626796</td>\n",
       "      <td>0.506044</td>\n",
       "      <td>0.556023</td>\n",
       "      <td>0.767688</td>\n",
       "      <td>0.703600</td>\n",
       "      <td>0.608086</td>\n",
       "      <td>0.598464</td>\n",
       "      <td>0.505665</td>\n",
       "      <td>0.528485</td>\n",
       "      <td>0.544064</td>\n",
       "      <td>0.559360</td>\n",
       "      <td>0.631007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.686641</td>\n",
       "      <td>0.718851</td>\n",
       "      <td>0.647651</td>\n",
       "      <td>0.591969</td>\n",
       "      <td>0.657447</td>\n",
       "      <td>0.706976</td>\n",
       "      <td>0.541668</td>\n",
       "      <td>0.487755</td>\n",
       "      <td>0.602116</td>\n",
       "      <td>0.456453</td>\n",
       "      <td>0.698304</td>\n",
       "      <td>0.744749</td>\n",
       "      <td>0.676810</td>\n",
       "      <td>0.614049</td>\n",
       "      <td>0.519503</td>\n",
       "      <td>0.544644</td>\n",
       "      <td>0.577835</td>\n",
       "      <td>0.678386</td>\n",
       "      <td>0.538932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.714121</td>\n",
       "      <td>0.680444</td>\n",
       "      <td>0.637762</td>\n",
       "      <td>0.620926</td>\n",
       "      <td>0.642751</td>\n",
       "      <td>0.606465</td>\n",
       "      <td>0.590615</td>\n",
       "      <td>0.545013</td>\n",
       "      <td>0.660674</td>\n",
       "      <td>0.610901</td>\n",
       "      <td>0.653513</td>\n",
       "      <td>0.700900</td>\n",
       "      <td>0.599802</td>\n",
       "      <td>0.606325</td>\n",
       "      <td>0.569190</td>\n",
       "      <td>0.512231</td>\n",
       "      <td>0.627211</td>\n",
       "      <td>0.647198</td>\n",
       "      <td>0.576110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.706643</td>\n",
       "      <td>0.694398</td>\n",
       "      <td>0.550952</td>\n",
       "      <td>0.570414</td>\n",
       "      <td>0.707609</td>\n",
       "      <td>0.689056</td>\n",
       "      <td>0.530546</td>\n",
       "      <td>0.524374</td>\n",
       "      <td>0.433448</td>\n",
       "      <td>0.348874</td>\n",
       "      <td>0.649959</td>\n",
       "      <td>0.670917</td>\n",
       "      <td>0.574331</td>\n",
       "      <td>0.552048</td>\n",
       "      <td>0.617516</td>\n",
       "      <td>0.323269</td>\n",
       "      <td>0.561446</td>\n",
       "      <td>0.549454</td>\n",
       "      <td>0.574215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.733267</td>\n",
       "      <td>0.804222</td>\n",
       "      <td>0.714299</td>\n",
       "      <td>0.765544</td>\n",
       "      <td>0.754832</td>\n",
       "      <td>0.735182</td>\n",
       "      <td>0.719914</td>\n",
       "      <td>0.734993</td>\n",
       "      <td>0.739563</td>\n",
       "      <td>0.744256</td>\n",
       "      <td>0.770388</td>\n",
       "      <td>0.794550</td>\n",
       "      <td>0.759482</td>\n",
       "      <td>0.732979</td>\n",
       "      <td>0.747177</td>\n",
       "      <td>0.728613</td>\n",
       "      <td>0.747042</td>\n",
       "      <td>0.725456</td>\n",
       "      <td>0.755559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.616948</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.584419</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.662906</td>\n",
       "      <td>0.606717</td>\n",
       "      <td>0.595170</td>\n",
       "      <td>0.635447</td>\n",
       "      <td>0.581364</td>\n",
       "      <td>0.560161</td>\n",
       "      <td>0.679305</td>\n",
       "      <td>0.634889</td>\n",
       "      <td>0.579733</td>\n",
       "      <td>0.590176</td>\n",
       "      <td>0.403130</td>\n",
       "      <td>0.573452</td>\n",
       "      <td>0.599843</td>\n",
       "      <td>0.451301</td>\n",
       "      <td>0.563047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.728199</td>\n",
       "      <td>0.703754</td>\n",
       "      <td>0.668563</td>\n",
       "      <td>0.710401</td>\n",
       "      <td>0.671483</td>\n",
       "      <td>0.667588</td>\n",
       "      <td>0.673620</td>\n",
       "      <td>0.634692</td>\n",
       "      <td>0.636284</td>\n",
       "      <td>0.696354</td>\n",
       "      <td>0.688852</td>\n",
       "      <td>0.693882</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>0.640544</td>\n",
       "      <td>0.621648</td>\n",
       "      <td>0.580569</td>\n",
       "      <td>0.653973</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.644766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.696116</td>\n",
       "      <td>0.746083</td>\n",
       "      <td>0.601951</td>\n",
       "      <td>0.626518</td>\n",
       "      <td>0.634062</td>\n",
       "      <td>0.627394</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.616524</td>\n",
       "      <td>0.498736</td>\n",
       "      <td>0.575160</td>\n",
       "      <td>0.662278</td>\n",
       "      <td>0.716771</td>\n",
       "      <td>0.654532</td>\n",
       "      <td>0.639141</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>0.579637</td>\n",
       "      <td>0.581021</td>\n",
       "      <td>0.609599</td>\n",
       "      <td>0.598062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.667357</td>\n",
       "      <td>0.673566</td>\n",
       "      <td>0.585908</td>\n",
       "      <td>0.621977</td>\n",
       "      <td>0.579194</td>\n",
       "      <td>0.611439</td>\n",
       "      <td>0.567259</td>\n",
       "      <td>0.548338</td>\n",
       "      <td>0.573924</td>\n",
       "      <td>0.455723</td>\n",
       "      <td>0.708692</td>\n",
       "      <td>0.662894</td>\n",
       "      <td>0.611094</td>\n",
       "      <td>0.686749</td>\n",
       "      <td>0.450539</td>\n",
       "      <td>0.405716</td>\n",
       "      <td>0.592497</td>\n",
       "      <td>0.595737</td>\n",
       "      <td>0.545714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.693586</td>\n",
       "      <td>0.673217</td>\n",
       "      <td>0.587229</td>\n",
       "      <td>0.623921</td>\n",
       "      <td>0.535108</td>\n",
       "      <td>0.692164</td>\n",
       "      <td>0.511676</td>\n",
       "      <td>0.538486</td>\n",
       "      <td>0.461888</td>\n",
       "      <td>0.492915</td>\n",
       "      <td>0.602562</td>\n",
       "      <td>0.636585</td>\n",
       "      <td>0.789323</td>\n",
       "      <td>0.600986</td>\n",
       "      <td>0.537875</td>\n",
       "      <td>0.568479</td>\n",
       "      <td>0.603659</td>\n",
       "      <td>0.535113</td>\n",
       "      <td>0.552010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.533819</td>\n",
       "      <td>0.584420</td>\n",
       "      <td>0.618539</td>\n",
       "      <td>0.704392</td>\n",
       "      <td>0.531402</td>\n",
       "      <td>0.555196</td>\n",
       "      <td>0.541591</td>\n",
       "      <td>0.482818</td>\n",
       "      <td>0.328047</td>\n",
       "      <td>0.370042</td>\n",
       "      <td>0.672706</td>\n",
       "      <td>0.659441</td>\n",
       "      <td>0.497635</td>\n",
       "      <td>0.578665</td>\n",
       "      <td>0.539592</td>\n",
       "      <td>0.389626</td>\n",
       "      <td>0.554712</td>\n",
       "      <td>0.523549</td>\n",
       "      <td>0.635768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.699318</td>\n",
       "      <td>0.737187</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.564011</td>\n",
       "      <td>0.696660</td>\n",
       "      <td>0.500708</td>\n",
       "      <td>0.510231</td>\n",
       "      <td>0.438427</td>\n",
       "      <td>0.551922</td>\n",
       "      <td>0.609413</td>\n",
       "      <td>0.717988</td>\n",
       "      <td>0.538786</td>\n",
       "      <td>0.644403</td>\n",
       "      <td>0.643313</td>\n",
       "      <td>0.614223</td>\n",
       "      <td>0.498901</td>\n",
       "      <td>0.556534</td>\n",
       "      <td>0.545108</td>\n",
       "      <td>0.573057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.703606</td>\n",
       "      <td>0.767834</td>\n",
       "      <td>0.676271</td>\n",
       "      <td>0.696193</td>\n",
       "      <td>0.725792</td>\n",
       "      <td>0.703918</td>\n",
       "      <td>0.708411</td>\n",
       "      <td>0.764920</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.664792</td>\n",
       "      <td>0.682439</td>\n",
       "      <td>0.710061</td>\n",
       "      <td>0.675886</td>\n",
       "      <td>0.677086</td>\n",
       "      <td>0.681589</td>\n",
       "      <td>0.769834</td>\n",
       "      <td>0.719032</td>\n",
       "      <td>0.679434</td>\n",
       "      <td>0.734910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.714991</td>\n",
       "      <td>0.751089</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.684413</td>\n",
       "      <td>0.732458</td>\n",
       "      <td>0.623710</td>\n",
       "      <td>0.641249</td>\n",
       "      <td>0.598881</td>\n",
       "      <td>0.587514</td>\n",
       "      <td>0.630449</td>\n",
       "      <td>0.741891</td>\n",
       "      <td>0.713734</td>\n",
       "      <td>0.737468</td>\n",
       "      <td>0.696663</td>\n",
       "      <td>0.651678</td>\n",
       "      <td>0.620481</td>\n",
       "      <td>0.643718</td>\n",
       "      <td>0.639980</td>\n",
       "      <td>0.688644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.781802</td>\n",
       "      <td>0.778168</td>\n",
       "      <td>0.708097</td>\n",
       "      <td>0.776715</td>\n",
       "      <td>0.690189</td>\n",
       "      <td>0.683193</td>\n",
       "      <td>0.752406</td>\n",
       "      <td>0.686410</td>\n",
       "      <td>0.614537</td>\n",
       "      <td>0.646968</td>\n",
       "      <td>0.757626</td>\n",
       "      <td>0.769703</td>\n",
       "      <td>0.774092</td>\n",
       "      <td>0.652555</td>\n",
       "      <td>0.703265</td>\n",
       "      <td>0.599287</td>\n",
       "      <td>0.629675</td>\n",
       "      <td>0.662410</td>\n",
       "      <td>0.684151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.766091</td>\n",
       "      <td>0.699343</td>\n",
       "      <td>0.544207</td>\n",
       "      <td>0.613286</td>\n",
       "      <td>0.511541</td>\n",
       "      <td>0.537623</td>\n",
       "      <td>0.574084</td>\n",
       "      <td>0.524298</td>\n",
       "      <td>0.551704</td>\n",
       "      <td>0.529589</td>\n",
       "      <td>0.707536</td>\n",
       "      <td>0.695018</td>\n",
       "      <td>0.606510</td>\n",
       "      <td>0.600237</td>\n",
       "      <td>0.565583</td>\n",
       "      <td>0.511988</td>\n",
       "      <td>0.593462</td>\n",
       "      <td>0.561607</td>\n",
       "      <td>0.542765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.752335</td>\n",
       "      <td>0.687595</td>\n",
       "      <td>0.561850</td>\n",
       "      <td>0.593588</td>\n",
       "      <td>0.656074</td>\n",
       "      <td>0.557013</td>\n",
       "      <td>0.525135</td>\n",
       "      <td>0.584130</td>\n",
       "      <td>0.463116</td>\n",
       "      <td>0.573555</td>\n",
       "      <td>0.719086</td>\n",
       "      <td>0.697383</td>\n",
       "      <td>0.663548</td>\n",
       "      <td>0.613760</td>\n",
       "      <td>0.414184</td>\n",
       "      <td>0.506891</td>\n",
       "      <td>0.593833</td>\n",
       "      <td>0.578192</td>\n",
       "      <td>0.602579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.781913</td>\n",
       "      <td>0.745677</td>\n",
       "      <td>0.572508</td>\n",
       "      <td>0.538457</td>\n",
       "      <td>0.596913</td>\n",
       "      <td>0.586368</td>\n",
       "      <td>0.544532</td>\n",
       "      <td>0.452849</td>\n",
       "      <td>0.553182</td>\n",
       "      <td>0.599497</td>\n",
       "      <td>0.704435</td>\n",
       "      <td>0.630855</td>\n",
       "      <td>0.648192</td>\n",
       "      <td>0.668830</td>\n",
       "      <td>0.560122</td>\n",
       "      <td>0.564311</td>\n",
       "      <td>0.544567</td>\n",
       "      <td>0.578871</td>\n",
       "      <td>0.628784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.632746</td>\n",
       "      <td>0.655082</td>\n",
       "      <td>0.419657</td>\n",
       "      <td>0.580166</td>\n",
       "      <td>0.503596</td>\n",
       "      <td>0.536378</td>\n",
       "      <td>0.492411</td>\n",
       "      <td>0.524652</td>\n",
       "      <td>0.341145</td>\n",
       "      <td>0.407413</td>\n",
       "      <td>0.592184</td>\n",
       "      <td>0.594237</td>\n",
       "      <td>0.536174</td>\n",
       "      <td>0.556114</td>\n",
       "      <td>0.379957</td>\n",
       "      <td>0.362794</td>\n",
       "      <td>0.436347</td>\n",
       "      <td>0.568336</td>\n",
       "      <td>0.493975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.683332</td>\n",
       "      <td>0.641083</td>\n",
       "      <td>0.646158</td>\n",
       "      <td>0.596164</td>\n",
       "      <td>0.552264</td>\n",
       "      <td>0.512580</td>\n",
       "      <td>0.486526</td>\n",
       "      <td>0.525339</td>\n",
       "      <td>0.497351</td>\n",
       "      <td>0.503923</td>\n",
       "      <td>0.691836</td>\n",
       "      <td>0.742888</td>\n",
       "      <td>0.593999</td>\n",
       "      <td>0.558450</td>\n",
       "      <td>0.496873</td>\n",
       "      <td>0.473589</td>\n",
       "      <td>0.516462</td>\n",
       "      <td>0.573239</td>\n",
       "      <td>0.553987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.686293</td>\n",
       "      <td>0.720332</td>\n",
       "      <td>0.623231</td>\n",
       "      <td>0.639555</td>\n",
       "      <td>0.658873</td>\n",
       "      <td>0.626176</td>\n",
       "      <td>0.612220</td>\n",
       "      <td>0.536975</td>\n",
       "      <td>0.555980</td>\n",
       "      <td>0.518341</td>\n",
       "      <td>0.737373</td>\n",
       "      <td>0.712737</td>\n",
       "      <td>0.676518</td>\n",
       "      <td>0.593676</td>\n",
       "      <td>0.531762</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.616002</td>\n",
       "      <td>0.710674</td>\n",
       "      <td>0.740369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.704005</td>\n",
       "      <td>0.780966</td>\n",
       "      <td>0.716666</td>\n",
       "      <td>0.721261</td>\n",
       "      <td>0.718245</td>\n",
       "      <td>0.691799</td>\n",
       "      <td>0.697129</td>\n",
       "      <td>0.668734</td>\n",
       "      <td>0.780218</td>\n",
       "      <td>0.909846</td>\n",
       "      <td>0.754765</td>\n",
       "      <td>0.787984</td>\n",
       "      <td>0.641656</td>\n",
       "      <td>0.704575</td>\n",
       "      <td>0.658977</td>\n",
       "      <td>0.615429</td>\n",
       "      <td>0.695378</td>\n",
       "      <td>0.687331</td>\n",
       "      <td>0.691566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.734609</td>\n",
       "      <td>0.695617</td>\n",
       "      <td>0.746091</td>\n",
       "      <td>0.646663</td>\n",
       "      <td>0.706116</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.688047</td>\n",
       "      <td>0.767865</td>\n",
       "      <td>0.659012</td>\n",
       "      <td>0.636696</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.766482</td>\n",
       "      <td>0.708097</td>\n",
       "      <td>0.740393</td>\n",
       "      <td>0.721918</td>\n",
       "      <td>0.772176</td>\n",
       "      <td>0.715932</td>\n",
       "      <td>0.665772</td>\n",
       "      <td>0.661768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.717389</td>\n",
       "      <td>0.780751</td>\n",
       "      <td>0.709042</td>\n",
       "      <td>0.703408</td>\n",
       "      <td>0.717947</td>\n",
       "      <td>0.715213</td>\n",
       "      <td>0.669416</td>\n",
       "      <td>0.597069</td>\n",
       "      <td>0.646378</td>\n",
       "      <td>0.697122</td>\n",
       "      <td>0.775905</td>\n",
       "      <td>0.785412</td>\n",
       "      <td>0.766779</td>\n",
       "      <td>0.736776</td>\n",
       "      <td>0.703295</td>\n",
       "      <td>0.614592</td>\n",
       "      <td>0.629262</td>\n",
       "      <td>0.707333</td>\n",
       "      <td>0.682489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.668833</td>\n",
       "      <td>0.775289</td>\n",
       "      <td>0.596872</td>\n",
       "      <td>0.609614</td>\n",
       "      <td>0.572160</td>\n",
       "      <td>0.520724</td>\n",
       "      <td>0.473414</td>\n",
       "      <td>0.490552</td>\n",
       "      <td>0.493824</td>\n",
       "      <td>0.468209</td>\n",
       "      <td>0.643731</td>\n",
       "      <td>0.630497</td>\n",
       "      <td>0.613450</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.473309</td>\n",
       "      <td>0.483122</td>\n",
       "      <td>0.564276</td>\n",
       "      <td>0.574078</td>\n",
       "      <td>0.559159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.598674</td>\n",
       "      <td>0.602582</td>\n",
       "      <td>0.465160</td>\n",
       "      <td>0.564052</td>\n",
       "      <td>0.470825</td>\n",
       "      <td>0.520067</td>\n",
       "      <td>0.418727</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>0.383903</td>\n",
       "      <td>0.355841</td>\n",
       "      <td>0.563064</td>\n",
       "      <td>0.549926</td>\n",
       "      <td>0.476887</td>\n",
       "      <td>0.511091</td>\n",
       "      <td>0.429263</td>\n",
       "      <td>0.423771</td>\n",
       "      <td>0.555681</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>0.475616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.758106</td>\n",
       "      <td>0.645967</td>\n",
       "      <td>0.648548</td>\n",
       "      <td>0.689090</td>\n",
       "      <td>0.704331</td>\n",
       "      <td>0.688249</td>\n",
       "      <td>0.648698</td>\n",
       "      <td>0.608870</td>\n",
       "      <td>0.667238</td>\n",
       "      <td>0.702690</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.659346</td>\n",
       "      <td>0.764046</td>\n",
       "      <td>0.647285</td>\n",
       "      <td>0.629118</td>\n",
       "      <td>0.697176</td>\n",
       "      <td>0.651879</td>\n",
       "      <td>0.633472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.575542</td>\n",
       "      <td>0.577105</td>\n",
       "      <td>0.491191</td>\n",
       "      <td>0.496631</td>\n",
       "      <td>0.326286</td>\n",
       "      <td>0.384118</td>\n",
       "      <td>0.348579</td>\n",
       "      <td>0.341068</td>\n",
       "      <td>0.357952</td>\n",
       "      <td>0.344221</td>\n",
       "      <td>0.682761</td>\n",
       "      <td>0.593354</td>\n",
       "      <td>0.539650</td>\n",
       "      <td>0.431355</td>\n",
       "      <td>0.355241</td>\n",
       "      <td>0.372097</td>\n",
       "      <td>0.479522</td>\n",
       "      <td>0.351961</td>\n",
       "      <td>0.452523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "channel       FP1       FP2        F3        F4        C3        C4        P3  \\\n",
       "measure     hurst     hurst     hurst     hurst     hurst     hurst     hurst   \n",
       "patient                                                                         \n",
       "1        0.753999  0.769921  0.664204  0.797222  0.717136  0.670598  0.717158   \n",
       "3        0.483106  0.553749  0.325695  0.478609  0.357043  0.346590  0.331214   \n",
       "4        0.590308  0.541832  0.408367  0.522805  0.420881  0.421173  0.317976   \n",
       "5        0.660602  0.671559  0.486952  0.552988  0.475865  0.490763  0.469610   \n",
       "7        0.639096  0.639857  0.553844  0.554577  0.461236  0.365423  0.436752   \n",
       "9        0.614442  0.635342  0.638403  0.622358  0.616017  0.606111  0.673701   \n",
       "10       0.724055  0.739994  0.641489  0.592656  0.590430  0.590867  0.594284   \n",
       "11       0.597459  0.661764  0.642293  0.652749  0.624995  0.705735  0.432528   \n",
       "12       0.832184  0.744612  0.707344  0.625504  0.652221  0.723436  0.739239   \n",
       "14       0.820025  0.836417  0.670636  0.695366  0.718106  0.751496  0.701602   \n",
       "15       0.789668  0.768005  0.669128  0.662312  0.685437  0.673983  0.671491   \n",
       "16       0.597817  0.607292  0.527661  0.557764  0.561065  0.602014  0.551127   \n",
       "17       0.554936  0.557657  0.515685  0.485301  0.424117  0.467076  0.436336   \n",
       "18       0.688870  0.655660  0.598123  0.583084  0.577431  0.542526  0.592951   \n",
       "19       0.616511  0.631594  0.553669  0.593662  0.467794  0.432599  0.494526   \n",
       "20       0.636589  0.675734  0.564011  0.459885  0.496038  0.471468  0.431317   \n",
       "22       0.613727  0.660269  0.642280  0.636919  0.663253  0.578787  0.591345   \n",
       "23       0.615167  0.661889  0.617417  0.590063  0.555753  0.569368  0.542934   \n",
       "24       0.690701  0.670268  0.524618  0.589364  0.597560  0.539645  0.505840   \n",
       "25       0.603308  0.591698  0.569239  0.552218  0.555800  0.563258  0.539206   \n",
       "26       0.623602  0.662135  0.502522  0.550089  0.499895  0.496693  0.317475   \n",
       "27       0.560730  0.592633  0.552116  0.527454  0.558303  0.506181  0.516698   \n",
       "28       0.542512  0.490586  0.481522  0.413476  0.534348  0.468061  0.323943   \n",
       "29       0.691098  0.700826  0.692508  0.626029  0.621230  0.579140  0.565149   \n",
       "30       0.772660  0.791092  0.706712  0.759470  0.672674  0.649862  0.682524   \n",
       "31       0.702028  0.687744  0.541059  0.553816  0.578532  0.489232  0.616714   \n",
       "32       0.607256  0.563812  0.416201  0.500108  0.430466  0.387784  0.386542   \n",
       "33       0.458505  0.453774  0.396653  0.367255  0.372247  0.408980  0.360121   \n",
       "34       0.776192  0.846239  0.700580  0.659454  0.700208  0.697899  0.656419   \n",
       "35       0.805447  0.799487  0.783529  0.814419  0.689170  0.671269  0.681100   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "96       0.536939  0.517970  0.344031  0.359802  0.428282  0.316459  0.418508   \n",
       "97       0.742351  0.725569  0.591421  0.568121  0.527010  0.525995  0.543318   \n",
       "99       0.659493  0.658699  0.553942  0.572075  0.581594  0.585257  0.541289   \n",
       "102      0.686641  0.718851  0.647651  0.591969  0.657447  0.706976  0.541668   \n",
       "103      0.714121  0.680444  0.637762  0.620926  0.642751  0.606465  0.590615   \n",
       "104      0.706643  0.694398  0.550952  0.570414  0.707609  0.689056  0.530546   \n",
       "106      0.733267  0.804222  0.714299  0.765544  0.754832  0.735182  0.719914   \n",
       "107      0.616948  0.667000  0.584419  0.600257  0.662906  0.606717  0.595170   \n",
       "108      0.728199  0.703754  0.668563  0.710401  0.671483  0.667588  0.673620   \n",
       "109      0.696116  0.746083  0.601951  0.626518  0.634062  0.627394  0.592787   \n",
       "110      0.667357  0.673566  0.585908  0.621977  0.579194  0.611439  0.567259   \n",
       "111      0.693586  0.673217  0.587229  0.623921  0.535108  0.692164  0.511676   \n",
       "112      0.533819  0.584420  0.618539  0.704392  0.531402  0.555196  0.541591   \n",
       "113      0.699318  0.737187  0.568881  0.564011  0.696660  0.500708  0.510231   \n",
       "114      0.703606  0.767834  0.676271  0.696193  0.725792  0.703918  0.708411   \n",
       "115      0.714991  0.751089  0.647059  0.684413  0.732458  0.623710  0.641249   \n",
       "116      0.781802  0.778168  0.708097  0.776715  0.690189  0.683193  0.752406   \n",
       "117      0.766091  0.699343  0.544207  0.613286  0.511541  0.537623  0.574084   \n",
       "119      0.752335  0.687595  0.561850  0.593588  0.656074  0.557013  0.525135   \n",
       "121      0.781913  0.745677  0.572508  0.538457  0.596913  0.586368  0.544532   \n",
       "122      0.632746  0.655082  0.419657  0.580166  0.503596  0.536378  0.492411   \n",
       "123      0.683332  0.641083  0.646158  0.596164  0.552264  0.512580  0.486526   \n",
       "124      0.686293  0.720332  0.623231  0.639555  0.658873  0.626176  0.612220   \n",
       "126      0.704005  0.780966  0.716666  0.721261  0.718245  0.691799  0.697129   \n",
       "127      0.734609  0.695617  0.746091  0.646663  0.706116  0.656600  0.688047   \n",
       "129      0.717389  0.780751  0.709042  0.703408  0.717947  0.715213  0.669416   \n",
       "130      0.668833  0.775289  0.596872  0.609614  0.572160  0.520724  0.473414   \n",
       "131      0.598674  0.602582  0.465160  0.564052  0.470825  0.520067  0.418727   \n",
       "132      0.740909  0.758106  0.645967  0.648548  0.689090  0.704331  0.688249   \n",
       "133      0.575542  0.577105  0.491191  0.496631  0.326286  0.384118  0.348579   \n",
       "\n",
       "channel        P4        O1        O2        F7        F8        T3        T4  \\\n",
       "measure     hurst     hurst     hurst     hurst     hurst     hurst     hurst   \n",
       "patient                                                                         \n",
       "1        0.729203  0.719521  0.714822  0.827080  0.739173  0.741375  0.683406   \n",
       "3        0.361492  0.311310  0.345450  0.488038  0.517441  0.370669  0.414256   \n",
       "4        0.387284  0.342726  0.433125  0.618258  0.565268  0.548987  0.660894   \n",
       "5        0.396751  0.421887  0.443163  0.586962  0.650928  0.528124  0.576462   \n",
       "7        0.470169  0.433260  0.455148  0.674387  0.679535  0.552409  0.571673   \n",
       "9        0.580958  0.553440  0.654507  0.693509  0.692508  0.589098  0.639489   \n",
       "10       0.610117  0.523190  0.615968  0.657750  0.670664  0.652542  0.600417   \n",
       "11       0.449657  0.538968  0.493138  0.683530  0.767805  0.592404  0.754489   \n",
       "12       0.601584  0.597490  0.567407  0.776553  0.806508  0.713681  0.763915   \n",
       "14       0.651476  0.646323  0.606984  0.779284  0.772223  0.767590  0.695606   \n",
       "15       0.732512  0.672579  0.684480  0.751451  0.744030  0.784964  0.567166   \n",
       "16       0.551095  0.416482  0.492067  0.665394  0.690520  0.622802  0.612296   \n",
       "17       0.442464  0.531152  0.462059  0.604143  0.671797  0.489966  0.485221   \n",
       "18       0.529432  0.627100  0.581733  0.665180  0.734811  0.530739  0.525505   \n",
       "19       0.389230  0.542843  0.545380  0.573196  0.638432  0.528256  0.588995   \n",
       "20       0.444567  0.498204  0.441731  0.621997  0.612477  0.503876  0.536234   \n",
       "22       0.568625  0.480604  0.513130  0.672477  0.715719  0.584699  0.567199   \n",
       "23       0.567487  0.537803  0.538646  0.619918  0.691923  0.581501  0.731185   \n",
       "24       0.567339  0.532469  0.574016  0.686415  0.655458  0.606180  0.535414   \n",
       "25       0.552314  0.366545  0.370824  0.628278  0.659876  0.589466  0.610678   \n",
       "26       0.394382  0.331280  0.349934  0.513452  0.650354  0.471623  0.603120   \n",
       "27       0.384636  0.475224  0.478286  0.627682  0.599159  0.521553  0.583006   \n",
       "28       0.397307  0.353085  0.336942  0.610790  0.572107  0.495354  0.542791   \n",
       "29       0.543224  0.606029  0.655466  0.705276  0.717293  0.723215  0.671282   \n",
       "30       0.636064  0.563478  0.745035  0.751163  0.747550  0.784203  0.724447   \n",
       "31       0.584733  0.502965  0.642458  0.646079  0.634877  0.543536  0.529998   \n",
       "32       0.375168  0.449297  0.478660  0.486930  0.551394  0.380094  0.422741   \n",
       "33       0.344535  0.362897  0.392919  0.624242  0.603409  0.450363  0.547260   \n",
       "34       0.625929  0.758093  0.683897  0.796750  0.820124  0.667095  0.846803   \n",
       "35       0.700588  0.702219  0.696712  0.753699  0.805501  0.730594  0.751616   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "96       0.352303  0.301375  0.251577  0.557938  0.577904  0.456063  0.439480   \n",
       "97       0.559898  0.518743  0.548919  0.735847  0.677587  0.641948  0.645336   \n",
       "99       0.626796  0.506044  0.556023  0.767688  0.703600  0.608086  0.598464   \n",
       "102      0.487755  0.602116  0.456453  0.698304  0.744749  0.676810  0.614049   \n",
       "103      0.545013  0.660674  0.610901  0.653513  0.700900  0.599802  0.606325   \n",
       "104      0.524374  0.433448  0.348874  0.649959  0.670917  0.574331  0.552048   \n",
       "106      0.734993  0.739563  0.744256  0.770388  0.794550  0.759482  0.732979   \n",
       "107      0.635447  0.581364  0.560161  0.679305  0.634889  0.579733  0.590176   \n",
       "108      0.634692  0.636284  0.696354  0.688852  0.693882  0.632534  0.640544   \n",
       "109      0.616524  0.498736  0.575160  0.662278  0.716771  0.654532  0.639141   \n",
       "110      0.548338  0.573924  0.455723  0.708692  0.662894  0.611094  0.686749   \n",
       "111      0.538486  0.461888  0.492915  0.602562  0.636585  0.789323  0.600986   \n",
       "112      0.482818  0.328047  0.370042  0.672706  0.659441  0.497635  0.578665   \n",
       "113      0.438427  0.551922  0.609413  0.717988  0.538786  0.644403  0.643313   \n",
       "114      0.764920  0.721867  0.664792  0.682439  0.710061  0.675886  0.677086   \n",
       "115      0.598881  0.587514  0.630449  0.741891  0.713734  0.737468  0.696663   \n",
       "116      0.686410  0.614537  0.646968  0.757626  0.769703  0.774092  0.652555   \n",
       "117      0.524298  0.551704  0.529589  0.707536  0.695018  0.606510  0.600237   \n",
       "119      0.584130  0.463116  0.573555  0.719086  0.697383  0.663548  0.613760   \n",
       "121      0.452849  0.553182  0.599497  0.704435  0.630855  0.648192  0.668830   \n",
       "122      0.524652  0.341145  0.407413  0.592184  0.594237  0.536174  0.556114   \n",
       "123      0.525339  0.497351  0.503923  0.691836  0.742888  0.593999  0.558450   \n",
       "124      0.536975  0.555980  0.518341  0.737373  0.712737  0.676518  0.593676   \n",
       "126      0.668734  0.780218  0.909846  0.754765  0.787984  0.641656  0.704575   \n",
       "127      0.767865  0.659012  0.636696  0.743982  0.766482  0.708097  0.740393   \n",
       "129      0.597069  0.646378  0.697122  0.775905  0.785412  0.766779  0.736776   \n",
       "130      0.490552  0.493824  0.468209  0.643731  0.630497  0.613450  0.590782   \n",
       "131      0.503597  0.383903  0.355841  0.563064  0.549926  0.476887  0.511091   \n",
       "132      0.648698  0.608870  0.667238  0.702690  0.685100  0.659346  0.764046   \n",
       "133      0.341068  0.357952  0.344221  0.682761  0.593354  0.539650  0.431355   \n",
       "\n",
       "channel        T5        T6        Fz        Cz        Pz  \n",
       "measure     hurst     hurst     hurst     hurst     hurst  \n",
       "patient                                                    \n",
       "1        0.732182  0.685296  0.741297  0.696825  0.734869  \n",
       "3        0.310522  0.359430  0.366019  0.382168  0.321377  \n",
       "4        0.355150  0.372977  0.392740  0.306597  0.343313  \n",
       "5        0.448159  0.357141  0.532884  0.582378  0.510804  \n",
       "7        0.334882  0.379694  0.507433  0.533982  0.557498  \n",
       "9        0.526527  0.632429  0.591804  0.619130  0.577964  \n",
       "10       0.546664  0.595402  0.619127  0.621813  0.633788  \n",
       "11       0.449896  0.616261  0.604243  0.631332  0.613122  \n",
       "12       0.576701  0.574221  0.576993  0.615871  0.747924  \n",
       "14       0.745911  0.594952  0.766869  0.704392  0.708301  \n",
       "15       0.768244  0.700240  0.616308  0.632860  0.685826  \n",
       "16       0.529462  0.533588  0.534114  0.616742  0.571664  \n",
       "17       0.411235  0.395726  0.447290  0.492999  0.502222  \n",
       "18       0.486485  0.508242  0.616264  0.614816  0.599599  \n",
       "19       0.463325  0.458552  0.350943  0.539782  0.512350  \n",
       "20       0.493150  0.412310  0.532143  0.543729  0.552986  \n",
       "22       0.484293  0.420215  0.539484  0.566527  0.561603  \n",
       "23       0.563603  0.580824  0.566481  0.619558  0.492312  \n",
       "24       0.449336  0.444196  0.523479  0.541581  0.576123  \n",
       "25       0.516875  0.463122  0.574401  0.607276  0.542476  \n",
       "26       0.381586  0.456057  0.527748  0.480016  0.357814  \n",
       "27       0.476249  0.424452  0.591344  0.584282  0.635061  \n",
       "28       0.329097  0.526325  0.376672  0.368591  0.409087  \n",
       "29       0.568964  0.795011  0.629653  0.611330  0.576465  \n",
       "30       0.683318  0.737370  0.579085  0.627251  0.616067  \n",
       "31       0.512648  0.529143  0.572759  0.523568  0.601014  \n",
       "32       0.363737  0.410484  0.530046  0.431840  0.485700  \n",
       "33       0.330751  0.320241  0.357159  0.409132  0.367891  \n",
       "34       0.623428  0.726842  0.705323  0.714835  0.671352  \n",
       "35       0.765304  0.715046  0.744174  0.661660  0.720400  \n",
       "...           ...       ...       ...       ...       ...  \n",
       "96       0.306535  0.307516  0.331909  0.351794  0.467706  \n",
       "97       0.563834  0.430974  0.576052  0.611643  0.609181  \n",
       "99       0.505665  0.528485  0.544064  0.559360  0.631007  \n",
       "102      0.519503  0.544644  0.577835  0.678386  0.538932  \n",
       "103      0.569190  0.512231  0.627211  0.647198  0.576110  \n",
       "104      0.617516  0.323269  0.561446  0.549454  0.574215  \n",
       "106      0.747177  0.728613  0.747042  0.725456  0.755559  \n",
       "107      0.403130  0.573452  0.599843  0.451301  0.563047  \n",
       "108      0.621648  0.580569  0.653973  0.664706  0.644766  \n",
       "109      0.605518  0.579637  0.581021  0.609599  0.598062  \n",
       "110      0.450539  0.405716  0.592497  0.595737  0.545714  \n",
       "111      0.537875  0.568479  0.603659  0.535113  0.552010  \n",
       "112      0.539592  0.389626  0.554712  0.523549  0.635768  \n",
       "113      0.614223  0.498901  0.556534  0.545108  0.573057  \n",
       "114      0.681589  0.769834  0.719032  0.679434  0.734910  \n",
       "115      0.651678  0.620481  0.643718  0.639980  0.688644  \n",
       "116      0.703265  0.599287  0.629675  0.662410  0.684151  \n",
       "117      0.565583  0.511988  0.593462  0.561607  0.542765  \n",
       "119      0.414184  0.506891  0.593833  0.578192  0.602579  \n",
       "121      0.560122  0.564311  0.544567  0.578871  0.628784  \n",
       "122      0.379957  0.362794  0.436347  0.568336  0.493975  \n",
       "123      0.496873  0.473589  0.516462  0.573239  0.553987  \n",
       "124      0.531762  0.402200  0.616002  0.710674  0.740369  \n",
       "126      0.658977  0.615429  0.695378  0.687331  0.691566  \n",
       "127      0.721918  0.772176  0.715932  0.665772  0.661768  \n",
       "129      0.703295  0.614592  0.629262  0.707333  0.682489  \n",
       "130      0.473309  0.483122  0.564276  0.574078  0.559159  \n",
       "131      0.429263  0.423771  0.555681  0.543360  0.475616  \n",
       "132      0.647285  0.629118  0.697176  0.651879  0.633472  \n",
       "133      0.355241  0.372097  0.479522  0.351961  0.452523  \n",
       "\n",
       "[110 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_dfs(col='lyap', kind='processed'):\n",
    "    df = pd.read_pickle(os.path.join(LABELED_ROOT, kind, col, f'training_{col}.pkl')).dropna()\n",
    "    df_bef = pd.read_pickle(os.path.join(LABELED_ROOT, kind, col, f'{col}_bef.pkl')).dropna()\n",
    "    df_aft = pd.read_pickle(os.path.join(LABELED_ROOT, kind, col, f'{col}_aft.pkl')).dropna()\n",
    "    return df, df_bef, df_aft\n",
    "    \n",
    "def prepare_resp_non(col='lyap'):\n",
    "    df, df_bef, df_aft = prepare_dfs(col)\n",
    "    return df[df['change'] >= df.quantile(0.66)['change']], df[df['change'] <= df.quantile(0.33)['change']]\n",
    "\n",
    "def prepare_dep_non(col='lyap'):\n",
    "    df, df_bef, df_aft = prepare_dfs(col)\n",
    "    df = df.drop(metapkl.columns, axis=1, errors='ignore')\n",
    "    df = df.join(metapkl)\n",
    "    return df[df['dep'] == 1], df[df['dep'] == -1]\n",
    "\n",
    "col = 'hurst'\n",
    "df, df_bef, df_aft = prepare_dfs(col)\n",
    "df_dep, df_nond = prepare_dep_non(col)\n",
    "df_dep # There are only 3 patients who were not cured - not enough data\n",
    "df_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import (SelectFromModel, RFE, RFECV, SelectKBest, mutual_info_classif)\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm, grid_search, datasets\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from functools import wraps\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def print_params(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f'{args} {kwargs}')\n",
    "        res = f(*args, **kwargs)\n",
    "        return res\n",
    "    return wrapper\n",
    "\n",
    "# @print_params\n",
    "def predict(lab, ba, cols, estimator, evaluate_on_all=False, channels=CHANNEL_NAMES, selector=None, \n",
    "            print_incorrectly_predicted=False):\n",
    "    df, df_bef, df_aft = prepare_dfs('all')\n",
    "    df = df.loc[(slice(None), slice(ba)), (channels, (cols))]\n",
    "    X = df\n",
    "    # X.columns = df.columns.droplevel(1)\n",
    "    X = X.drop(metapkl.columns, axis=1, errors='ignore')\n",
    "    y = X.join(metapkl)[lab]\n",
    "    X = X[y.isin([-1, 1])]\n",
    "    y = y[y.isin([-1, 1])]\n",
    "    \n",
    "    if selector is not None:\n",
    "        X = selector.transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(\n",
    "            X, y, test_size=0.3, random_state=213)\n",
    "    \n",
    "    # unique, counts = np.unique(y_train, return_counts=True) \n",
    "    # print(counts[0] / (counts[0] + counts[1]))\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    print('Training distribution: ', dict(zip(unique, counts)))\n",
    "    unique, counts = np.unique(y_test, return_counts=True)\n",
    "    print('Testing distribution: ', dict(zip(unique, counts)))\n",
    "\n",
    "    y_train = y_train.astype('int')\n",
    "\n",
    "    estimator = estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    y_pred = y_pred.astype('int')\n",
    "    y_test = y_test.astype('int')\n",
    "    \n",
    "    if hasattr(estimator, 'support_'):\n",
    "        # print('Selected columns: ', X.columns.values[estimator.support_])\n",
    "        pass\n",
    "    print(\"Accuracy score: %.2f\" % metrics.accuracy_score(y_test, y_pred))\n",
    "    print('Confusion matrix:\\n', metrics.confusion_matrix(y_test, y_pred))\n",
    "    print('Precision score: ', metrics.precision_score(y_test, y_pred, average='weighted'))\n",
    "    print('Recall score: ', metrics.recall_score(y_test, y_pred, average='weighted'))\n",
    "    print('f1 score: ', metrics.f1_score(y_test, y_pred, average='weighted'))\n",
    "    print('ROC AUC score: ', metrics.roc_auc_score(y_test, y_pred, average='weighted'))\n",
    "    # print('Coefficients: \\n', np.array(X.stack().columns)[estimator.support_])\n",
    "    \n",
    "    if print_incorrectly_predicted:\n",
    "        y_pred_s = pd.Series(y_pred, index=y_test.index)\n",
    "        print('Incorrectly predicted:')\n",
    "        print(pd.DataFrame(y_test[y_pred != y_test]).join(X))\n",
    "    \n",
    "    if evaluate_on_all:\n",
    "        y_pred = estimator.predict(X)\n",
    "        y_pred = y_pred.astype('int')\n",
    "\n",
    "        print(\"Accuracy score: %.2f\" % metrics.accuracy_score(y, y_pred))\n",
    "        print('Confusion matrix:\\n', metrics.confusion_matrix(y, y_pred))\n",
    "        print('Precision score: ', metrics.precision_score(y, y_pred, average='weighted'))\n",
    "        print('Recall score: ', metrics.recall_score(y, y_pred, average='weighted'))\n",
    "        print('f1 score: ', metrics.f1_score(y, y_pred, average='weighted'))\n",
    "        print('ROC AUC score: ', metrics.roc_auc_score(y, y_pred, average='weighted'))\n",
    "        if print_incorrectly_predicted:\n",
    "            y_pred_s = pd.Series(y_pred, index=y.index)\n",
    "            print('Incorrectly predicted:')\n",
    "            print(pd.DataFrame(y[y_pred != y]).join(X))\n",
    "    return estimator\n",
    "\n",
    "\n",
    "def scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    # return metrics.accuracy_score(y, y_pred)\n",
    "    # return (metrics.f1_score(y, y_pred, average='weighted', labels=np.unique(y_pred)))\n",
    "            # + metrics.precision_score(y, y_pred, average='weighted') \n",
    "            # + metrics.recall_score(y, y_pred, average='weighted') \n",
    "            # + metrics.accuracy_score(y, y_pred))\n",
    "    return metrics.roc_auc_score(y, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  {-1: 51, 1: 47}\n",
      "Testing distribution:  {-1: 23, 1: 19}\n",
      "Accuracy score: 0.45\n",
      "Confusion matrix:\n",
      " [[10 13]\n",
      " [10  9]]\n",
      "Precision score:  0.4588744588744589\n",
      "Recall score:  0.4523809523809524\n",
      "f1 score:  0.4533128055533047\n",
      "ROC AUC score:  0.454233409610984\n",
      "Training distribution:  {-1: 51, 1: 47}\n",
      "Testing distribution:  {-1: 23, 1: 19}\n",
      "Accuracy score: 0.60\n",
      "Confusion matrix:\n",
      " [[15  8]\n",
      " [ 9 10]]\n",
      "Precision score:  0.5935846560846562\n",
      "Recall score:  0.5952380952380952\n",
      "f1 score:  0.5940743174785729\n",
      "ROC AUC score:  0.5892448512585812\n",
      "Training distribution:  {-1: 51, 1: 47}\n",
      "Testing distribution:  {-1: 23, 1: 19}\n",
      "Accuracy score: 0.45\n",
      "Confusion matrix:\n",
      " [[ 0 23]\n",
      " [ 0 19]]\n",
      "Precision score:  0.2046485260770975\n",
      "Recall score:  0.4523809523809524\n",
      "f1 score:  0.2818110850897736\n",
      "ROC AUC score:  0.5\n",
      "Training distribution:  {-1: 51, 1: 47}\n",
      "Testing distribution:  {-1: 23, 1: 19}\n",
      "Accuracy score: 0.50\n",
      "Confusion matrix:\n",
      " [[ 3 20]\n",
      " [ 1 18]]\n",
      "Precision score:  0.625\n",
      "Recall score:  0.5\n",
      "f1 score:  0.4074074074074074\n",
      "ROC AUC score:  0.5389016018306636\n",
      "Training distribution:  {-1: 51, 1: 47}\n",
      "Testing distribution:  {-1: 23, 1: 19}\n",
      "Accuracy score: 0.48\n",
      "Confusion matrix:\n",
      " [[16  7]\n",
      " [15  4]]\n",
      "Precision score:  0.4471442535958665\n",
      "Recall score:  0.47619047619047616\n",
      "f1 score:  0.4451499118165785\n",
      "ROC AUC score:  0.45308924485125857\n",
      "Training distribution:  {-1: 51, 1: 47}\n",
      "Testing distribution:  {-1: 23, 1: 19}\n",
      "Accuracy score: 0.52\n",
      "Confusion matrix:\n",
      " [[10 13]\n",
      " [ 7 12]]\n",
      "Precision score:  0.5392717086834734\n",
      "Recall score:  0.5238095238095238\n",
      "f1 score:  0.5205627705627706\n",
      "ROC AUC score:  0.5331807780320366\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "estimator_svc = grid_search.GridSearchCV(svm.SVC(class_weight='balanced'), {\n",
    "    'C': [0.02, 0.5, 1.0, 1.5, 2],\n",
    "    # 'kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "    'shrinking': (True, False),\n",
    "    # 'decision_function_shape' : ('ovo', 'ovr'),\n",
    "}, iid=False, scoring=scorer)\n",
    "\n",
    "estimator_lg = grid_search.GridSearchCV(LogisticRegression(class_weight='balanced'), {\n",
    "    'C': [0.5, 1.0, 1.5, 2, 2.5, 3, 3.5],\n",
    "    'penalty': ['l2', 'l1'],\n",
    "}, iid=False, scoring=scorer)\n",
    "\n",
    "estimators = {\n",
    "    svm.SVC(class_weight='balanced'): {\n",
    "        'C': [0.02, 0.5, 1.0, 1.5, 2],\n",
    "        # 'kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "        'shrinking': (True, False),\n",
    "        # 'decision_function_shape' : ('ovo', 'ovr'),\n",
    "    },\n",
    "    LogisticRegression(class_weight='balanced'): {\n",
    "        'C': [0.5, 1.0, 1.5, 2, 2.5, 3, 3.5],\n",
    "        'penalty': ['l2', 'l1'],\n",
    "    }\n",
    "}\n",
    "\n",
    "estimators = {\n",
    "    svm.SVC(kernel='linear', class_weight='balanced') : {},\n",
    "    # LogisticRegression(C=1, class_weight='balanced') : {},\n",
    "}\n",
    "\n",
    "cols = ('lyap', 'corr', 'dfa', 'sampen')\n",
    "\n",
    "for estimator, params in estimators.items():\n",
    "    # for cols in (('dfa', 'higu'),):\n",
    "    # for cols in (('dfa', 'higu', 'hurst'), ('dfa',), ('higu',), ('hurst'), ('dfa', 'hurst')):\n",
    "    for cols in (('dfa', 'higu', 'hurst', 'sampen', 'lyap'), ('dfa',), ('higu',), ('hurst',), ('sampen',), ('lyap',)):\n",
    "    # for cols in (('dfa',), ('dfa', 'lyap'), ('dfa', 'sampen'), ('dfa', 'corr')):\n",
    "        for selector in (GeneticSelectionCV(estimator,\n",
    "                                          cv=3,\n",
    "                                          verbose=0,\n",
    "                                          scoring=scorer,\n",
    "                                          n_population=50,\n",
    "                                          crossover_proba=0.8,\n",
    "                                          mutation_proba=0.2,\n",
    "                                          n_generations=50,\n",
    "                                          crossover_independent_proba=0.5,\n",
    "                                          mutation_independent_proba=0.05,\n",
    "                                          tournament_size=3,\n",
    "                                          caching=True,\n",
    "                                          n_jobs=-1),):\n",
    "            # selector = grid_search.GridSearchCV(selector, params, iid=False, scoring=scorer)\n",
    "            predict('resp', None, cols, selector)\n",
    "            # predict('dep_bef', 'a', cols, selector.estimator.estimator)\n",
    "            # predict('dep_aft', 'b', cols, selector)\n",
    "            # predict('resp', 'b', cols, selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depressed / Nondepressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  {-1: 15, 1: 24}\n",
      "Testing distribution:  {-1: 11, 1: 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (2 levels on the left, 1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.53\n",
      "Confusion matrix:\n",
      " [[4 7]\n",
      " [1 5]]\n",
      "Precision score:  0.6647058823529413\n",
      "Recall score:  0.5294117647058824\n",
      "f1 score:  0.5196078431372549\n",
      "ROC AUC score:  0.5984848484848485\n",
      "Accuracy score: 0.75\n",
      "Confusion matrix:\n",
      " [[17  9]\n",
      " [ 5 25]]\n",
      "Precision score:  0.752673796791444\n",
      "Recall score:  0.75\n",
      "f1 score:  0.7473958333333333\n",
      "ROC AUC score:  0.7435897435897437\n"
     ]
    }
   ],
   "source": [
    "# dfa_def, L 10, H 30, 88\n",
    "estimator = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "selector = GeneticSelectionCV(\n",
    "    estimator,\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    scoring=scorer,\n",
    "    n_population=50,\n",
    "    crossover_proba=0.8,\n",
    "    mutation_proba=0.2,\n",
    "    n_generations=50,\n",
    "    crossover_independent_proba=0.5,\n",
    "    mutation_independent_proba=0.05,\n",
    "    tournament_size=3,\n",
    "    caching=True,\n",
    "    n_jobs=-1)\n",
    "selector = predict('dep', None, ('lyap'), selector, evaluate_on_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  {-1: 29, 1: 33}\n",
      "Testing distribution:  {-1: 11, 1: 16}\n",
      "Accuracy score: 0.67\n",
      "Confusion matrix:\n",
      " [[ 5  6]\n",
      " [ 3 13]]\n",
      "Precision score:  0.6600877192982456\n",
      "Recall score:  0.6666666666666666\n",
      "f1 score:  0.6546365914786968\n",
      "Incorrectly predicted:\n",
      "               dep  (FP2, lyap)  (F3, lyap)  (F4, lyap)\n",
      "patient trial                                          \n",
      "106     a        1     8.217972    9.394106    9.039179\n",
      "36      b       -1    11.363785   11.071076   11.037363\n",
      "103     b       -1    10.071514   10.692004   10.524601\n",
      "113     b        1     8.071585    9.121098    6.944322\n",
      "107     b       -1     8.880156   10.363891    9.807452\n",
      "130     a        1     8.956714    9.002172    9.214503\n",
      "3       b       -1    11.302472   11.271126   11.381274\n",
      "75      b       -1    11.019301   10.931988   11.019289\n",
      "115     b       -1    10.337421   10.198964   10.465757\n",
      "Accuracy score: 0.58\n",
      "Confusion matrix:\n",
      " [[22 18]\n",
      " [19 30]]\n",
      "Precision score:  0.5852630857769252\n",
      "Recall score:  0.5842696629213483\n",
      "f1 score:  0.5846929596881333\n",
      "Incorrectly predicted:\n",
      "              dep  (FP2, lyap)  (F3, lyap)  (F4, lyap)\n",
      "patient trial                                         \n",
      "3       b      -1    11.302472   11.271126   11.381274\n",
      "5       b       1    10.364009    9.902109    9.551293\n",
      "10      a       1     8.587235    8.304111    8.648945\n",
      "12      a       1     8.606021    8.862489    9.546337\n",
      "        b      -1     8.188641    8.665411   10.588183\n",
      "17      a       1     8.928190    8.487922    8.528657\n",
      "18      a       1     7.103452    6.896109    7.650140\n",
      "23      b      -1     9.826911    9.389708    9.899074\n",
      "25      b      -1     9.970360   10.021755   10.027530\n",
      "26      a       1     9.889050    9.494859    9.288179\n",
      "28      b      -1    11.427094   10.586041   10.908855\n",
      "36      b      -1    11.363785   11.071076   11.037363\n",
      "41      a       1     8.683222    9.346080    9.093884\n",
      "44      b      -1     9.352508    9.498618    9.837858\n",
      "46      b      -1    10.461911    9.717135    9.952261\n",
      "52      a       1    11.074046    9.323025   10.144851\n",
      "        b      -1    11.084560   10.396520   10.671835\n",
      "56      a       1    11.396427    8.733277   10.442751\n",
      "57      b      -1     8.993978    9.484208    9.955286\n",
      "71      b      -1    10.212011   10.271055   10.382972\n",
      "75      b      -1    11.019301   10.931988   11.019289\n",
      "76      a       1     9.403115    9.311642    9.303922\n",
      "77      a       1     8.946969    9.382414    9.159431\n",
      "83      b       1    11.714081    9.418028    9.702518\n",
      "89      a       1     7.344097    6.843944    7.286874\n",
      "91      a       1     7.691135    8.703163    7.329716\n",
      "97      b      -1     9.213833    9.714308    9.669247\n",
      "102     b      -1    11.200146   10.126247   10.326183\n",
      "103     b      -1    10.071514   10.692004   10.524601\n",
      "104     a       1     8.651921    7.896256    8.922529\n",
      "106     a       1     8.217972    9.394106    9.039179\n",
      "107     b      -1     8.880156   10.363891    9.807452\n",
      "113     a       1     8.393263    8.965002    7.112245\n",
      "        b       1     8.071585    9.121098    6.944322\n",
      "115     b      -1    10.337421   10.198964   10.465757\n",
      "119     b      -1    10.864712   10.305223    9.961157\n",
      "130     a       1     8.956714    9.002172    9.214503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (2 levels on the left, 1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "estimator = predict('dep', None, ('lyap',), estimator, evaluate_on_all=True, \n",
    "                    channels=('F3', 'F4', 'FP2'), print_incorrectly_predicted=True)\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  {-1: 15, 1: 24}\n",
      "Testing distribution:  {-1: 11, 1: 6}\n",
      "Accuracy score: 0.53\n",
      "Confusion matrix:\n",
      " [[3 8]\n",
      " [0 6]]\n",
      "Precision score:  0.7983193277310924\n",
      "Recall score:  0.5294117647058824\n",
      "f1 score:  0.48907563025210077\n",
      "Incorrectly predicted:\n",
      "               dep  (O1, dfa)  (T4, dfa)  (T5, dfa)  (T6, dfa)  (Cz, dfa)\n",
      "patient trial                                                            \n",
      "3       b       -1   0.243963   0.466208   0.369881   0.283775   0.350899\n",
      "75      b       -1   0.437848   0.787615   0.491093   0.491635   0.669573\n",
      "63      b       -1   0.686631   0.578315   0.540581   0.544454   0.570220\n",
      "111     b       -1   0.712939   0.599738   0.391483   0.486671   0.455653\n",
      "115     b       -1   0.470486   0.663665   0.509812   0.508774   0.630070\n",
      "97      b       -1   0.557046   0.718987   0.521811   0.488559   0.644719\n",
      "77      b       -1   0.156859   0.309606   0.425798   0.414859   0.566363\n",
      "23      b       -1   0.623567   0.704339   0.551867   0.573251   0.554170\n",
      "Accuracy score: 0.64\n",
      "Confusion matrix:\n",
      " [[11 15]\n",
      " [ 5 25]]\n",
      "Precision score:  0.6540178571428571\n",
      "Recall score:  0.6428571428571429\n",
      "f1 score:  0.6258503401360545\n",
      "Incorrectly predicted:\n",
      "              dep  (O1, dfa)  (T4, dfa)  (T5, dfa)  (T6, dfa)  (Cz, dfa)\n",
      "patient trial                                                           \n",
      "3       b      -1   0.243963   0.466208   0.369881   0.283775   0.350899\n",
      "10      a       1   0.561337   0.671103   0.639762   0.589966   0.681309\n",
      "15      b      -1   0.554491   0.637901   0.562665   0.472687   0.598435\n",
      "23      b      -1   0.623567   0.704339   0.551867   0.573251   0.554170\n",
      "28      b      -1   0.203480   0.441564   0.242224   0.347047   0.249022\n",
      "30      a       1   0.539912   1.112272   0.885905   0.902842   0.699837\n",
      "32      b      -1   0.525433   0.597786   0.473488   0.484357   0.493055\n",
      "33      b      -1   0.423102   0.452431   0.329313   0.334108   0.512885\n",
      "47      b      -1   0.409704   0.574868   0.497696   0.402489   0.602960\n",
      "56      a       1   0.768081   0.958621   0.765522   0.818864   0.700456\n",
      "63      b      -1   0.686631   0.578315   0.540581   0.544454   0.570220\n",
      "75      b      -1   0.437848   0.787615   0.491093   0.491635   0.669573\n",
      "77      b      -1   0.156859   0.309606   0.425798   0.414859   0.566363\n",
      "89      a       1   0.762447   0.734930   0.680326   0.646010   0.767153\n",
      "92      b      -1   0.585426   0.642316   0.477619   0.536022   0.480322\n",
      "97      b      -1   0.557046   0.718987   0.521811   0.488559   0.644719\n",
      "104     b      -1   0.343564   0.538886   0.357184   0.303871   0.455310\n",
      "106     a       1   0.914357   0.902474   0.980158   0.858242   0.936175\n",
      "111     b      -1   0.712939   0.599738   0.391483   0.486671   0.455653\n",
      "115     b      -1   0.470486   0.663665   0.509812   0.508774   0.630070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (2 levels on the left, 1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L 12, H 28\n",
    "estimator = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "estimator = predict('dep', None, ('dfa',), estimator, evaluate_on_all=True, \n",
    "                    channels=('T4', 'T5', 'T6', 'Cz', 'O1'), print_incorrectly_predicted=True) # DFA_def\n",
    "# estimator = predict('dep', None, ('dfa',), estimator, evaluate_on_all=False, \n",
    "#                     channels=('Fz',), print_incorrectly_predicted=False) # DFA_arit_no_overlap\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (2 levels on the left, 1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  {-1: 15, 1: 24}\n",
      "Testing distribution:  {-1: 11, 1: 6}\n",
      "Accuracy score: 0.71\n",
      "Confusion matrix:\n",
      " [[6 5]\n",
      " [0 6]]\n",
      "Precision score:  0.839572192513369\n",
      "Recall score:  0.7058823529411765\n",
      "f1 score:  0.7058823529411764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. , 6.5,\n",
       "       7. , 7.5, 8. , 8.5, 9. , 9.5]), 'kernel': ('linear', 'poly', 'rbf', 'sigmoid'), 'degree': [2, 3, 4, 5], 'shrinking': (True, False), 'decision_function_shape': ('ovo', 'ovr'), 'class_weight': ['balanced', {-1: 1, 1: 1.2}]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = grid_search.GridSearchCV(estimator, {\n",
    "    'C': np.arange(0.5, 10, 0.5),\n",
    "    'kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "    'degree': [2, 3, 4, 5],\n",
    "    'shrinking': (True, False),\n",
    "    'decision_function_shape' : ('ovo', 'ovr'),\n",
    "    'class_weight' : ['balanced', {-1: 1, 1: 1.2}]\n",
    "}, scoring=None)\n",
    "\n",
    "predict('dep', None, ('dfa'), gs, evaluate_on_all=False, channels=('T4', 'T5', 'T6', 'Cz', 'O1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kovar/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (2 levels on the left, 1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  {-1: 15, 1: 24}\n",
      "Testing distribution:  {-1: 11, 1: 6}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-63d63ad70c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m })\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dep'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'lyap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_on_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FP2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, channels=('T4', 'T5', 'T6', 'Cz', 'O1', 'O2'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a55d9a3dd18e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(lab, ba, cols, estimator, evaluate_on_all, channels, selector, print_incorrectly_predicted)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gs = grid_search.GridSearchCV(estimator, {\n",
    "    'C': np.arange(0.5, 10, 0.5),\n",
    "    'kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "    'degree': [2, 3, 4, 5],\n",
    "    'shrinking': (True, False),\n",
    "    'decision_function_shape' : ('ovo', 'ovr'),\n",
    "    'class_weight' : ['balanced', {-1: 1, 1: 1.2}]\n",
    "})\n",
    "\n",
    "predict('dep', None, ('lyap'), gs, evaluate_on_all=True, channels=('F3', 'F4', 'FP2')) #, channels=('T4', 'T5', 'T6', 'Cz', 'O1', 'O2'))\n",
    "gs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
